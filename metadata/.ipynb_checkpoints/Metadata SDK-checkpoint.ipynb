{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have each Python cell auto-formatted\n",
    "# See: https://black.readthedocs.io\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata SDK\n",
    "\n",
    "## Introduction\n",
    "All information about executions, models, data sets as well as the files and objects that are a part of a machine learning workflow are referred to as metadata.\n",
    "The [Metadata SDK](https://www.kubeflow.org/docs/components/metadata/) allows you to manage all ML assets:\n",
    "\n",
    "- An [`Execution`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Execution) captures metadata of a single run of an ML workflow, which can be either a pipeline or a notebook. Any derived data that is used or produced in the context of a single execution is referred to as an **artifact**.\n",
    "- Metadata of a [`Model`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Model) includes a URI to its location, a name and description, training framework (e.g. TensorFlow, PyTorch, MXNet), hyperparameters and their values, and so on.\n",
    "- [`Metrics`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Metrics) collect evaluation metrics of the model\n",
    "- A [`DataSet`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.DataSet) describes the data that is either the input or output of a component within an ML workflow.\n",
    "\n",
    "Behind the scenes, the Metadata SDK uses the gRPC service of [MLMD](https://github.com/google/ml-metadata/blob/master/g3doc/get_started.md), the ML Metadata library, which was originally designed for [TFX](https://github.com/tensorflow/tfx) (TensorFlow eXtended) and offers both implementations for SQLite and MySQL.\n",
    "\n",
    "With the Metadata SDK you can also add so-called [metadata watchers](https://github.com/kubeflow/metadata/blob/master/watcher/README.md) to check up on Kubernetes resource changes and to save the related data in the metadata service.\n",
    "\n",
    "### What You'll Learn\n",
    "In this notebook, you'll learn how to use the Metadata SDK to display information about executions and interact with the metadata available within Kubeflow.\n",
    "\n",
    "### What You'll Need\n",
    "Nothing except this notebook.\n",
    "\n",
    "## How to Create a Workspace\n",
    "A [workspace](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Workspace) is a grouping of pipelines, notebooks, and their artifacts.\n",
    "A single workspace can hold multiple executions.\n",
    "\n",
    "To define various objects (e.g. executions, runs, models) you therefore need to create a workspace.\n",
    "Unless you define multiple workspaces within the same context, you do not have to specify it after you have created \n",
    "\n",
    "Let's import the metadata modules and store the default DNS for the host as well as the port for the [metadata store](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Store) in a couple of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.metadata import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "METADATA_STORE_HOST = \"metadata-grpc-service.kubeflow\"\n",
    "METADATA_STORE_PORT = 8080\n",
    "\n",
    "METADATA_STORE = metadata.Store(\n",
    "    grpc_host=METADATA_STORE_HOST, grpc_port=METADATA_STORE_PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = metadata.Workspace(\n",
    "    store=METADATA_STORE,\n",
    "    name=\"demo workspace\",\n",
    "    description=\"A workspace for our demo\",\n",
    "    labels={\"some_key\": \"a-value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a `demo workspace` with a custom label `some_key` that holds the `a-value`.\n",
    "Labels are typically used to enable easier filtering.\n",
    "These are (as of yet) not part of the Kubeflow central dashboard, but they can be used to filter by means of the SDK.\n",
    "\n",
    "## How to Create a Run in a Workspace\n",
    "The difference between runs and executions is subtle: an execution records the run of a component or step in a machine learning workflow (along with its runtime parameters).\n",
    "\n",
    "A run is an instance of an executable step. \n",
    "\n",
    "An execution therefore always _refers_ to a run.\n",
    "\n",
    "We'll also define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def add_suffix(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Appends an underscore and hexidecimal UUID to `name`\n",
    "\n",
    "    :param str name: String to be suffixed\n",
    "    :return: Suffixed string\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return f\"{name}_{uuid4().hex}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run itself is then defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = metadata.Run(\n",
    "    workspace=ws, name=add_suffix(\"run\"), description=\"A run in our workspace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Create an Execution of a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: 19\n"
     ]
    }
   ],
   "source": [
    "exec = metadata.Execution(\n",
    "    name=add_suffix(\"execution\"),\n",
    "    workspace=ws,\n",
    "    run=run,\n",
    "    description=\"An execution of our run\",\n",
    ")\n",
    "\n",
    "print(f\"Execution ID: {exec.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Log Artifacts for an Execution\n",
    "An execution can have both _input_ and _output_ artifacts.\n",
    "Artifacts that can be logged for executions are `Model`, `DataSet`, `Metrics`, or a [custom artifact type](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Artifact).\n",
    "\n",
    "You can see defined artifacts by navigating to the Kubeflow Central Dashboard's Artifact Store.\n",
    "\n",
    "\n",
    "### How to Log a Data Set\n",
    "A data set that is used by the model itself is an input artifact.\n",
    "It can be registered as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set ID:      25\n",
      "Data set version: ds_2f9dd04cf4584b87bd670ad474879b85\n"
     ]
    }
   ],
   "source": [
    "date_set_version = add_suffix(\"ds\")\n",
    "\n",
    "data_set = exec.log_input(\n",
    "    metadata.DataSet(\n",
    "        description=\"Sample data\",\n",
    "        name=\"mytable-dump\",\n",
    "        owner=\"owner@my-company.com\",\n",
    "        uri=\"file://path/to/dataset\",\n",
    "        version=date_set_version,\n",
    "        query=\"SELECT * FROM mytable\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Data set ID:      {data_set.id}\")\n",
    "print(f\"Data set version: {data_set.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data itself is available at the specified `uri`.\n",
    "The `query` is optional and _documents_ how this data is fetched from the source.\n",
    "It is not used to retrieve it.\n",
    "After all, the data does not have to live in a relational database at all.\n",
    "\n",
    "### How to Log a Model\n",
    "If a step of a machine learning workflow generates a model, it is logged as an output artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:      26\n",
      "Model version: model_fb6da2a4ea0c4bb5be7a42fc09221797\n"
     ]
    }
   ],
   "source": [
    "model_version = add_suffix(\"model\")\n",
    "\n",
    "model = exec.log_output(\n",
    "    metadata.Model(\n",
    "        name=\"MNIST\",\n",
    "        description=\"Model to recognize handwritten digits\",\n",
    "        owner=\"owner@my-company.com\",\n",
    "        uri=\"gcs://my-bucket/mnist\",\n",
    "        model_type=\"neural network\",\n",
    "        training_framework={\"name\": \"tensorflow\", \"version\": \"v1.0\"},\n",
    "        hyperparameters={\n",
    "            \"learning_rate\": 0.5,\n",
    "            \"layers\": [10, 3, 1],\n",
    "            \"early_stop\": True,\n",
    "        },\n",
    "        version=model_version,\n",
    "        labels={\"a_label\": \"some-value\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Model ID:      {model.id}\")\n",
    "print(f\"Model version: {model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason it is an output artifact is simple yet perhaps not obvious: until a model has been run (i.e. trained) its weights and values are not yet computed.\n",
    "The trained model is therefore the output of a step in the workflow.\n",
    "\n",
    "Please note that the model type is a [free-form text field](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Model). Only `uri` and `name` are required, although `version` is highly recommended.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Models as Input Artifacts</b><br>\n",
    "    You may wonder whether a model can ever be an input artifact.<br>\n",
    "    The answer is: Yes!<br><br>Model serving is probably the most common case for a model to be listed as an input artifact to an execution, but there is another possibility.\n",
    "    In transfer learning, the knowledge gained from a base model is 'transferred' to another problem that is related but different.\n",
    "    Suppose you have to build an application to classify pictures of drinks into four categories: tea, coffee, soft drinks, and alcohol.\n",
    "    The basic task of identifying cups, mugs, glasses, liquids, and so on requires a lot of data and hardware, so it makes sense to rely on a pre-trained network for feature extraction.\n",
    "    Since the (dense) layers near the output of the model are more specific to the task at hand than the (convolutional) layers near the input, you cut the base network after the convolutional layers and add in your own dense layers to perform the necessary task-dependent classification.\n",
    "    The problem of classifying drinks is related to image recognition, and the knowledge gained from the latter (i.e. features extracted that are needed to classify general images) is transferred to the former.\n",
    "    If your own data set is huge, the recommendation is to train the base model.\n",
    "    If, however, your own data set is small, it's advantageous to freeze the base model. \n",
    "    The base model is then an input artifact to an execution.<br><br>\n",
    "    Examples of classifiers based on pre-trained base models (e.g. <a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\">cats vs dogs (in TensorFlow)</a>, <a href=\"https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\">ants vs bees (in PyTorch)</a>, <a href=\"https://gluon-cv.mxnet.io/build/examples_classification/transfer_learning_minc.html\">various materials (in MXNet)</a>) are available in case you want to know more.\n",
    "</div>\n",
    "\n",
    "### How to Log the Evaluation of a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics ID: 27\n"
     ]
    }
   ],
   "source": [
    "metrics = exec.log_output(\n",
    "    metadata.Metrics(\n",
    "        name=\"MNIST evaluation\",\n",
    "        description=\"Evaluation of the MNIST model\",\n",
    "        owner=\"owner@my-company.com\",\n",
    "        uri=\"gcs://my-bucket/mnist-eval.csv\",\n",
    "        data_set_id=str(data_set.id),\n",
    "        model_id=str(model.id),\n",
    "        metrics_type=metadata.Metrics.VALIDATION,\n",
    "        values={\"accuracy\": 0.95},\n",
    "        labels={\"mylabel\": \"l1\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Metrics ID: {metrics.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible values for `metrics_type`:\n",
    "- `TRAINING`\n",
    "- `VALIDATION`\n",
    "- `TESTING`\n",
    "- `PRODUCTION`\n",
    "\n",
    "If you are not familiar with the distinction between validation and training, please check out the [notebook on hyperparameter tuning](../katib/Hyperparameter%20Tuning.ipynb), which explains the difference and the need for an additional evaluation step.\n",
    "\n",
    "## How to Add Metadata for Serving the Model\n",
    "Once you're satisfied with the model, you want to serve it.\n",
    "The model server is an execution with a model as input artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving model with ID:      26\n",
      "Serving model with version: model_fb6da2a4ea0c4bb5be7a42fc09221797\n"
     ]
    }
   ],
   "source": [
    "app = metadata.Execution(\n",
    "    name=\"Serving the MNIST model\",\n",
    "    workspace=ws,\n",
    "    description=\"An execution to represent the model serving component\",\n",
    ")\n",
    "\n",
    "served_model = metadata.Model(\n",
    "    name=\"MNIST\", uri=\"gcs://my-bucket/mnist\", version=model.version,\n",
    ")\n",
    "\n",
    "m = app.log_input(served_model)\n",
    "\n",
    "print(f\"Serving model with ID:      {m.id}\")\n",
    "print(f\"Serving model with version: {m.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we use the `name`, `uri`, and `version` to identify the model.\n",
    "As stated before, only the first two are required, but it's a good practice to also include the version.\n",
    "\n",
    "## How to List All Models in a Workspace\n",
    "The Artifact Store is user interface that displays artifacts across all workspaces.\n",
    "Not all fields are available, which means we cannot filter easily on, say, custom labels.\n",
    "\n",
    "Fortunately, we can ask for all artifacts of a certain type: `Model`, `Metrics`, `DataSet`, or a custom artifact.\n",
    "Here's how to list all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26,\n",
       "  'workspace': 'demo workspace',\n",
       "  'run': 'run_5faf20cfbba941c9a400fbfbe02cd654',\n",
       "  'model_type': 'neural network',\n",
       "  'create_time': '2020-04-20T13:21:12.320745Z',\n",
       "  'version': 'model_fb6da2a4ea0c4bb5be7a42fc09221797',\n",
       "  'owner': 'owner@my-company.com',\n",
       "  'description': 'Model to recognize handwritten digits',\n",
       "  'name': 'MNIST',\n",
       "  'uri': 'gcs://my-bucket/mnist',\n",
       "  'training_framework': {'name': 'tensorflow', 'version': 'v1.0'},\n",
       "  'hyperparameters': {'learning_rate': 0.5,\n",
       "   'layers': [10, 3, 1],\n",
       "   'early_stop': True},\n",
       "  'labels': {'a_label': 'some-value'},\n",
       "  'kwargs': {}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = ws.list(metadata.Model.ARTIFACT_TYPE_NAME)\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is not exactly fabulous for humans, so we can restructure it to make it easier to manipulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>workspace</th>\n",
       "      <th>run</th>\n",
       "      <th>model_type</th>\n",
       "      <th>create_time</th>\n",
       "      <th>version</th>\n",
       "      <th>owner</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>uri</th>\n",
       "      <th>training_framework</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>labels</th>\n",
       "      <th>kwargs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>demo workspace</td>\n",
       "      <td>run_5faf20cfbba941c9a400fbfbe02cd654</td>\n",
       "      <td>neural network</td>\n",
       "      <td>2020-04-20T13:21:12.320745Z</td>\n",
       "      <td>model_fb6da2a4ea0c4bb5be7a42fc09221797</td>\n",
       "      <td>owner@my-company.com</td>\n",
       "      <td>Model to recognize handwritten digits</td>\n",
       "      <td>MNIST</td>\n",
       "      <td>gcs://my-bucket/mnist</td>\n",
       "      <td>{'name': 'tensorflow', 'version': 'v1.0'}</td>\n",
       "      <td>{'learning_rate': 0.5, 'layers': [10, 3, 1], '...</td>\n",
       "      <td>{'a_label': 'some-value'}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       workspace                                   run      model_type  \\\n",
       "0  26  demo workspace  run_5faf20cfbba941c9a400fbfbe02cd654  neural network   \n",
       "\n",
       "                   create_time                                 version  \\\n",
       "0  2020-04-20T13:21:12.320745Z  model_fb6da2a4ea0c4bb5be7a42fc09221797   \n",
       "\n",
       "                  owner                            description   name  \\\n",
       "0  owner@my-company.com  Model to recognize handwritten digits  MNIST   \n",
       "\n",
       "                     uri                         training_framework  \\\n",
       "0  gcs://my-bucket/mnist  {'name': 'tensorflow', 'version': 'v1.0'}   \n",
       "\n",
       "                                     hyperparameters  \\\n",
       "0  {'learning_rate': 0.5, 'layers': [10, 3, 1], '...   \n",
       "\n",
       "                      labels kwargs  \n",
       "0  {'a_label': 'some-value'}     {}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the output includes the labels.\n",
    "Labels are particularly helpful when monitoring many (versions of) models in production, both with regard to system and model performance, as both can affect the overall user experience; a bad prediction (e.g. recommendation) from a responsive service negatively affects the user experience, as does an unresponsive service with good predictions.\n",
    "Model as well as system performance metrics need to be tracked over time and across versions to ensure a solid user experience.\n",
    "With (shared) labels it's possible to monitor both simultaneously.\n",
    "\n",
    "## How to Track Lineage\n",
    "The same is true of executions and artifacts that belong to certain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executions related to the model: {19, 20}\n",
      "Artifacts related to the trainer: {25, 26, 27}\n"
     ]
    }
   ],
   "source": [
    "model_events = ws.store.get_events_by_artifact_ids([model.id])\n",
    "\n",
    "execution_ids = set(e.execution_id for e in model_events)\n",
    "print(f\"Executions related to the model: {execution_ids}\")\n",
    "\n",
    "trainer_events = ws.store.get_events_by_execution_ids([exec.id])\n",
    "artifact_ids = set(e.artifact_id for e in trainer_events)\n",
    "print(f\"Artifacts related to the trainer: {artifact_ids}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
