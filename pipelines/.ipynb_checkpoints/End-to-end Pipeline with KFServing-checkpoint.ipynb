{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kubeflow Pipelines\n",
    "\n",
    "## Introduction\n",
    "With [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/) you can build entire workflows that automate the steps involved in going from training a machine learning model to actually serving an optimized version of it.\n",
    "These steps can be triggered automatically by a CI/CD workflow or on demand from a command line or notebook.\n",
    "\n",
    "Kubeflow Pipelines (`kfp`) comes with a user interface for managing and tracking experiments, jobs, and runs.\n",
    "A pipeline is a description of a machine learning workflow, replete with all inputs and outputs.\n",
    "In Kubeflow Pipelines, an **experiment** is a [workspace](../metadata/Metadata%20SDK.ipynb) where you can _experiment with_ different configuration of your pipelines.\n",
    "Experiments are a way to organize runs of jobs into logical groups.\n",
    "A **run** is simply a single execution (instance) of a pipeline.\n",
    "Kubeflow Pipelines also supports recurring runs, which is a repeatable run of a pipeline.\n",
    "Based on a so-called **run trigger** an instance of a pipeline with its run configuration is periodically started.\n",
    "As of now, [run triggers](https://www.kubeflow.org/docs/pipelines/overview/concepts/run-trigger/) are time-based (i.e. not event-based).\n",
    "\n",
    "In the UI, there is a pictorial representation of the runtime execution of a pipeline.\n",
    "This **graph** consists of one or more steps (i.e. nodes).\n",
    "Each step\n",
    "The directed edges (arrows) show the parent/child relationship: A &rarr; B means that B depends on A; B cannot start until A has successfully completed.\n",
    "\n",
    "A **component** performs a single step in the pipeline (e.g. data ingestion, data preprocessing, data transformation, model training, hyperparameter tuning).\n",
    "It is analogous to a function: it has a name, (metadata) parameters and return values (interface), and a body (implementation).\n",
    "It must therefore be self-contained.\n",
    "Each component must be packaged as a Docker image.\n",
    "Please note that components are independently executed: they do not share the same process and cannot share in-memory data.\n",
    "\n",
    "### What You'll Learn\n",
    "This notebook trains a simple (MNIST) model in TensorFlow and serves it with [KFServing](https://www.kubeflow.org/docs/components/serving/kfserving/), which is a serverless inference server.\n",
    "What this means is that you do not have to worry about which machines it runs on, networking, autoscaling, health checks, and what have you.\n",
    "Instead, you can focus on what matters to you: the model and a REST API you can call for predictions.\n",
    "If you are familiar with Kubernetes, you can even do [out-of-the-box canary deployments](https://github.com/kubeflow/kfserving/tree/master/docs/samples/tensorflow), in which a percentage of traffic is directed to the 'canary (in the coal mine)' with the latest model to ensure it functions properly before completely rolling out any (potentially problematic) updates.\n",
    "\n",
    "If you prefer to use a more sophisticated model or a PyTorch-based one, you can check out the relevant notebooks: [MNIST with TensorFlow](../training/tensorflow/MNIST%20with%20TensorFlow.ipynb) or [MNIST with PyTorch](../training/pytorch/MNIST%20with%20PyTorch.ipynb).\n",
    "\n",
    "KFServing reads the model file from [MinIO](https://min.io/), an open-source S3-compliant object storage tool, which is already included with your Kubeflow installation.\n",
    "\n",
    "We also use MinIO to provide the input data set to the pipeline. This way it can run without a connection to the Internet.\n",
    "\n",
    "### What You'll Need\n",
    "This notebook.\n",
    "\n",
    "## Prerequisites\n",
    "Let's make sure Kubeflow Pipelines is available:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Copy input data set into MinIO using its CLI\n",
    "\n",
    "First, we configure credentials for `mc`, the MinIO command line client.\n",
    "We then use it to create a bucket, upload the dataset to it, and set access policy so that the pipeline can download it from MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32mAdded `minio` successfully.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ./mc alias set minio http://minio-service.kubeflow:9000 mlopstestnplink D6N1ErV++1pUSrjGPZCW48UKMSEzxMf1884l5j/eqk99ZkIMbgpmUTRFs3zPsZGWX42iD7IwdwDTxr9ZNHPTeA=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;3mmc: <ERROR> \u001b[0m\u001b[33;3mUnable to make bucket `minio/bucket5`. Your previous request to create the named bucket succeeded and you already own it.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ./mc mb minio/bucket5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...ts.tar.gz:  27.10 MiB / 27.10 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 34.26 MiB/s 0s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[31;3;1mmc: <ERROR> \u001b[0m\u001b[31;3;1mUnable to set policy `download` for `minio/bucket5`. unsupported Resource found [arn:aws:s3:::bucket5/*] for action s3:GetBucketLocation.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! tar --dereference -czf datasets.tar.gz ./datasets\n",
    "! ./mc cp datasets.tar.gz minio/bucket5/datasets.tar.gz\n",
    "! ./mc policy set download minio/bucket5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to Implement Kubeflow Pipelines Components\n",
    "As we said before, components are self-contained pieces of code: Python functions.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    The function must be completely self-contained.\n",
    "    No code (incl. imports) can be defined outside of the body itself.\n",
    "    All imports <a href=\"https://www.kubeflow.org/docs/pipelines/sdk/lightweight-python-components/\">must be included</a> in the function body itself!\n",
    "    Imported packages must be available in the base image.<br><br>\n",
    "    Why? Because each component will be packaged as a Docker image.\n",
    "    The base image must therefore contain all dependencies.\n",
    "    Any dependencies you install manually in the notebook are invisible to the Python function once it's inside the image.\n",
    "    The function itself becomes the entrypoint of the image, which is why all auxiliary functions must be defined inside the function.\n",
    "    That does cause some unfortunate duplication, but it also means you do not have to worry about the mechanism of packaging, as we shall see below.\n",
    "</div>\n",
    "\n",
    "For our pipeline, we shall define four components:\n",
    "- Download the MNIST data set\n",
    "- Train the TensorFlow model\n",
    "- Evaluate the trained model\n",
    "- Export the trained model\n",
    "- Serve the trained model\n",
    "\n",
    "We also need the current Kubernetes namespace, which we can dynamically grab using [Kubeflow Fairing](../fairing/Kubeflow%20Fairing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "import kfp.components as components\n",
    "import kfp.dsl as dsl\n",
    "import kubeflow.fairing.utils\n",
    "\n",
    "from kfp.components import InputPath, OutputPath\n",
    "\n",
    "NAMESPACE = kubeflow.fairing.utils.get_current_k8s_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Function arguments specified with `InputPath` and `OutputPath` are the key to defining dependencies.\n",
    "For now, it suffices to think of them as the input and output of each step.\n",
    "How we can define dependencies is explained in the [next section](#How-to-Combine-the-Components-into-a-Pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Component 1: Download the MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_dataset(data_dir: OutputPath(str)):\n",
    "    \"\"\"Download the MNIST data set to the KFP volume to share it among all steps\"\"\"\n",
    "    import urllib.request\n",
    "    import tarfile\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    url = \"http://minio-service.kubeflow:9000/bucket5/datasets.tar.gz\"\n",
    "    stream = urllib.request.urlopen(url)\n",
    "    tar = tarfile.open(fileobj=stream, mode=\"r|gz\")\n",
    "    tar.extractall(path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Component 2: Train the Model\n",
    "For both the training and evaluation we must divide the integer-valued pixel values by 255 to scale all values into the [0, 1] (floating-point) range.\n",
    "This function must be copied into both component functions (cf. `normalize_image`).\n",
    "\n",
    "If you wish to learn more about the model code, please have a look at the [MNIST with TensorFlow](../training/MNIST%20with%20TensorFlow.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(data_dir: InputPath(str), model_dir: OutputPath(str)):\n",
    "    \"\"\"Trains a single-layer CNN for 5 epochs using a pre-downloaded dataset.\n",
    "    Once trained, the model is persisted to `model_dir`.\"\"\"\n",
    "\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    def normalize_image(image, label):\n",
    "        \"\"\"Normalizes images: `uint8` -> `float32`\"\"\"\n",
    "        return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    ds_train, ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=\"train\",\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "        download=False,\n",
    "        data_dir=f\"{data_dir}/datasets\",\n",
    "    )\n",
    "\n",
    "    # See: https://www.tensorflow.org/datasets/keras_example#build_training_pipeline\n",
    "    ds_train = ds_train.map(\n",
    "        normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=5,\n",
    "    )\n",
    "\n",
    "    model.save(model_dir)\n",
    "    print(f\"Model saved {model_dir}\")\n",
    "    print(os.listdir(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter Tuning with Katib\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Hyperparameter tuning is the process of optimizing a model's hyperparameter values in order to maximize the predictive quality of the model.\n",
    "Examples of such hyperparameters are the learning rate, neural architecture depth (layers) and width (nodes), epochs, batch size, dropout rate, and activation functions.\n",
    "These are the parameters that are set prior to training; unlike the model parameters (weights and biases), these do not change during the process of training the model.\n",
    "\n",
    "[Katib](https://github.com/kubeflow/katib) automates the process of hyperparameter tuning by running a pre-configured number of training jobs (known as **trials**) in parallel.\n",
    "Each trial evaluates a different set of hyperparameter configurations.\n",
    "Within each **experiment** it automatically adjusts the hyperparameters to find their optimal values with regard to the objective function, which is typically the model's metric (e.g. accuracy, AUC, F1, precision).\n",
    "An experiment therefore consists of an objective, a search space for the hyperparameters, and a [search algorithm](https://github.com/kubeflow/katib#hyperparameter-tuning).\n",
    "At the end of the experiment, Katib outputs the optimized values, which are also known as **suggestions**.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Three Data Sets</b><br>Whereas it is common to have training and test data sets in traditional (supervised) machine learning, in deep learning (esp. when combined with hyperparameter tuning), it is recommended to have a three-way split: training, validation (a.k.a. as development), and test. \n",
    "    The training data set is, as always, to learn parameters (weights and biases) from data. \n",
    "    The test data set is also known as the hold-out set and its sole purpose is to check the model's hypothesis of parameter values in terms of how well it generalizes to data it has never come across.\n",
    "    The point of the validation data set is to cross-validate the model and tweak the hyperparameters. \n",
    "    Since information from this data set is used to adjust the model, it is not an objective test of the model's generalizability. \n",
    "    It is not unlike a <a href=\\\"https://www.linkedin.com/posts/activity-6424581736302284800-Kdas\\\">teacher checking up on students</a>:\n",
    "    <ul>\n",
    "      <li>The training data set is the text book to learn the theory from</li>\n",
    "      <li>The validation data set comprises the exercises to practice the theory</li>\n",
    "      <li>The test data set is exam to assess the degree of learning vs lookup</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### What You'll Learn\n",
    "This notebook shows how you can create and configure an `Experiment` for both `TensorFlow` and `PyTorch` training jobs.\n",
    "In terms of Kubernetes, such an experiment is a custom resource handled by the Katib operator.\n",
    "\n",
    "### What You'll Need\n",
    "A Docker image with either a [TensorFlow](../training/tensorflow/MNIST%20with%20TensorFlow.ipynb) or [PyTorch](../training/pytorch/MNIST%20with%20PyTorch.ipynb) model that accepts hyperparameters as arguments.\n",
    "Please click on the links to see such models.\n",
    "\n",
    "That's it, so let's get started!\n",
    "\n",
    "## How to Specify Hyperparameters in Your Models\n",
    "In order for Katib to be able to tweak hyperparameters it needs to know what these are called in the model.\n",
    "Beyond that, the model must specify these hyperparameters either as regular (command line) parameters or as environment variables.\n",
    "Since the model needs to be containerized, any command line parameters or environment variables must to be passed to the container that holds your model.\n",
    "By far the most common and also the recommended way is to use command line parameters that are captured with [`argparse`](https://docs.python.org/3/library/argparse.html) or similar; the trainer (function) then uses their values internally.\n",
    "\n",
    "## How to Expose Model Metrics as Objective Functions\n",
    "By default, Katib collects metrics from the standard output of a job container by using a sidecar container.\n",
    "In order to make the metrics available to Katib, they must be logged to [stdout](https://www.kubeflow.org/docs/components/hyperparameter-tuning/experiment/#metrics-collector) in the `key=value` format.\n",
    "The job output will be redirected to `/var/log/katib/metrics.log` file.\n",
    "This means that the objective function (for Katib) must match the metric's `key` in the models output.\n",
    "It's therefore possible to define custom model metrics for your use case.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Sidecars</b><br>\n",
    "    In the sidecar (a.k.a. sidekick or decomposition) pattern, if you are not already familiar with it, a secondary (sidecar) container is attached to the primary workload inside a pod in Kubernetes. In many cases, pods run a single container, but peripheral services, such as networking services, monitoring, and logging, are required in all applications and services. With sidecars there is no need to re-implement basic but secondary tasks in each service or application. The sidecar has the same lifecycle as the primary application and it has access to the same resources. The sidecar is, however, isolated from the main container, which means it does not have to be implemented in the same technology. This means it can easily be reused across various workloads.<br><br>\n",
    "    Katib does not care whether you use TensorFlow, PyTorch, MXNet, or any other framework for that matter. All it needs to do its job is a (parameterized) trainer container and the logs to grab the model's metrics from.\n",
    "</div>\n",
    "\n",
    "## How to Create Experiments\n",
    "Before we proceed, let's set up a few basic definitions that we can re-use.\n",
    "Note that you typically use (YAML) resource definitions for Kubernetes from the command line, but we shall show you how to do everything from a notebook, so that you do not have to exit your favourite environment at all!\n",
    "Of course, if you are more familiar or comfortable with `kubectl` and the command line, feel free to use a local CLI or the embedded terminals from the Jupyter Lab launch screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment.kubeflow.org/test unchanged\n"
     ]
    }
   ],
   "source": [
    "! kubectl apply -f katib.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Component 3: Evaluate the Model\n",
    "With the following Python function the model is evaluated.\n",
    "The metrics [metadata](https://www.kubeflow.org/docs/pipelines/sdk/pipelines-metrics/) (loss and accuracy) is available to the Kubeflow Pipelines UI.\n",
    "Metadata can automatically be visualized with output viewer(s).\n",
    "Please go [here](https://www.kubeflow.org/docs/pipelines/sdk/output-viewer/) to see how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    data_dir: InputPath(str), model_dir: InputPath(str), metrics_path: OutputPath(str)\n",
    ") -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `/mlpipeline-metrics.json` for Kubeflow Pipelines\n",
    "    metadata.\"\"\"\n",
    "\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "    from collections import namedtuple\n",
    "\n",
    "    def normalize_image(image, label):\n",
    "        return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "    ds_test, ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=\"test\",\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "        download=False,\n",
    "        data_dir=f\"{data_dir}/datasets\",\n",
    "    )\n",
    "\n",
    "    # See: https://www.tensorflow.org/datasets/keras_example#build_training_pipeline\n",
    "    ds_test = ds_test.map(\n",
    "        normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    (loss, accuracy) = model.evaluate(ds_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"loss\", \"numberValue\": str(loss), \"format\": \"PERCENTAGE\"},\n",
    "            {\"name\": \"accuracy\", \"numberValue\": str(accuracy), \"format\": \"PERCENTAGE\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "\n",
    "    return out_tuple(json.dumps(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Component 4: Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_model(\n",
    "    model_dir: InputPath(str),\n",
    "    metrics: InputPath(str),\n",
    "    export_bucket: str,\n",
    "    model_name: str,\n",
    "    model_version: int,\n",
    "):\n",
    "    import os\n",
    "    import boto3\n",
    "    from botocore.client import Config\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=\"http://minio-service.kubeflow:9000\",\n",
    "        aws_access_key_id=\"mlopstestnplink\",\n",
    "        aws_secret_access_key=\"D6N1ErV++1pUSrjGPZCW48UKMSEzxMf1884l5j/eqk99ZkIMbgpmUTRFs3zPsZGWX42iD7IwdwDTxr9ZNHPTeA==\",\n",
    "        config=Config(signature_version=\"s3v4\"),\n",
    "    )\n",
    "\n",
    "    # Create export bucket if it does not yet exist\n",
    "    response = s3.list_buckets()\n",
    "    export_bucket_exists = False\n",
    "\n",
    "    for bucket in response[\"Buckets\"]:\n",
    "        if bucket[\"Name\"] == export_bucket:\n",
    "            export_bucket_exists = True\n",
    "\n",
    "    if not export_bucket_exists:\n",
    "        s3.create_bucket(ACL=\"public-read-write\", Bucket=export_bucket)\n",
    "\n",
    "    # Save model files to S3\n",
    "    for root, dirs, files in os.walk(model_dir):\n",
    "        for filename in files:\n",
    "            local_path = os.path.join(root, filename)\n",
    "            s3_path = os.path.relpath(local_path, model_dir)\n",
    "\n",
    "            s3.upload_file(\n",
    "                local_path,\n",
    "                export_bucket,\n",
    "                f\"{model_name}/{model_version}/{s3_path}\",\n",
    "                ExtraArgs={\"ACL\": \"public-read\"},\n",
    "            )\n",
    "\n",
    "    response = s3.list_objects(Bucket=export_bucket)\n",
    "    print(f\"All objects in {export_bucket}:\")\n",
    "    for file in response[\"Contents\"]:\n",
    "        print(\"{}/{}\".format(export_bucket, file[\"Key\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metadata SDK\n",
    "\n",
    "## Introduction\n",
    "All information about executions, models, data sets as well as the files and objects that are a part of a machine learning workflow are referred to as metadata.\n",
    "The [Metadata SDK](https://www.kubeflow.org/docs/components/metadata/) allows you to manage all ML assets:\n",
    "\n",
    "- An [`Execution`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Execution) captures metadata of a single run of an ML workflow, which can be either a pipeline or a notebook. Any derived data that is used or produced in the context of a single execution is referred to as an **artifact**.\n",
    "- Metadata of a [`Model`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Model) includes a URI to its location, a name and description, training framework (e.g. TensorFlow, PyTorch, MXNet), hyperparameters and their values, and so on.\n",
    "- [`Metrics`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Metrics) collect evaluation metrics of the model\n",
    "- A [`DataSet`](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.DataSet) describes the data that is either the input or output of a component within an ML workflow.\n",
    "\n",
    "Behind the scenes, the Metadata SDK uses the gRPC service of [MLMD](https://github.com/google/ml-metadata/blob/master/g3doc/get_started.md), the ML Metadata library, which was originally designed for [TFX](https://github.com/tensorflow/tfx) (TensorFlow eXtended) and offers both implementations for SQLite and MySQL.\n",
    "\n",
    "With the Metadata SDK you can also add so-called [metadata watchers](https://github.com/kubeflow/metadata/blob/master/watcher/README.md) to check up on Kubernetes resource changes and to save the related data in the metadata service.\n",
    "\n",
    "### What You'll Learn\n",
    "In this notebook, you'll learn how to use the Metadata SDK to display information about executions and interact with the metadata available within Kubeflow.\n",
    "\n",
    "### What You'll Need\n",
    "Nothing except this notebook.\n",
    "\n",
    "## How to Create a Workspace\n",
    "A [workspace](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Workspace) is a grouping of pipelines, notebooks, and their artifacts.\n",
    "A single workspace can hold multiple executions.\n",
    "\n",
    "To define various objects (e.g. executions, runs, models) you therefore need to create a workspace.\n",
    "Unless you define multiple workspaces within the same context, you do not have to specify it after you have created \n",
    "\n",
    "Let's import the metadata modules and store the default DNS for the host as well as the port for the [metadata store](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Store) in a couple of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kubeflow.metadata\n",
    "from kubeflow.metadata import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210319 08:40:43 metadata_store:80] MetadataStore with gRPC connection initialized\n"
     ]
    }
   ],
   "source": [
    "METADATA_STORE_HOST = \"metadata-grpc-service.kubeflow\"\n",
    "METADATA_STORE_PORT = 8080\n",
    "\n",
    "METADATA_STORE = metadata.Store(\n",
    "    grpc_host=METADATA_STORE_HOST, grpc_port=METADATA_STORE_PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210319 08:40:43 metadata_store:80] MetadataStore with gRPC connection initialized\n"
     ]
    }
   ],
   "source": [
    "ws1 = metadata.Workspace(\n",
    "    # Connect to metadata service in namespace kubeflow in k8s cluster.\n",
    "    store=metadata.Store(grpc_host=METADATA_STORE_HOST, grpc_port=METADATA_STORE_PORT),\n",
    "    name=\"Mnist Workspace\",\n",
    "    description=\"Artifact on Mnist Workspace\",\n",
    "    labels={\"n1\": \"v1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This creates a `demo workspace` with a custom label `some_key` that holds the `a-value`.\n",
    "Labels are typically used to enable easier filtering.\n",
    "These are (as of yet) not part of the Kubeflow central dashboard, but they can be used to filter by means of the SDK.\n",
    "\n",
    "## How to Create a Run in a Workspace\n",
    "The difference between runs and executions is subtle: an execution records the run of a component or step in a machine learning workflow (along with its runtime parameters).\n",
    "\n",
    "A run is an instance of an executable step. \n",
    "\n",
    "An execution therefore always _refers_ to a run.\n",
    "\n",
    "We'll also define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def add_suffix(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Appends an underscore and hexidecimal UUID to `name`\n",
    "\n",
    "    :param str name: String to be suffixed\n",
    "    :return: Suffixed string\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    return f\"{name}_{uuid4().hex}\"\n",
    "\n",
    "\n",
    "run = metadata.Run(\n",
    "    workspace=ws1,\n",
    "    name=add_suffix(\"run\"),\n",
    "    description=\"A run in our workspace\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to Create an Execution of a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: 40\n"
     ]
    }
   ],
   "source": [
    "exec = metadata.Execution(\n",
    "    name=add_suffix(\"execution\"),\n",
    "    workspace=ws1,\n",
    "    run=run,\n",
    "    description=\"An execution of our run\",\n",
    ")\n",
    "\n",
    "print(f\"Execution ID: {exec.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to Log Artifacts for an Execution\n",
    "An execution can have both _input_ and _output_ artifacts.\n",
    "Artifacts that can be logged for executions are `Model`, `DataSet`, `Metrics`, or a [custom artifact type](https://kubeflow-metadata.readthedocs.io/en/latest/source/md.html#kubeflow.metadata.metadata.Artifact).\n",
    "\n",
    "You can see defined artifacts by navigating to the Kubeflow Central Dashboard's Artifact Store.\n",
    "\n",
    "\n",
    "### How to Log a Data Set\n",
    "A data set that is used by the model itself is an input artifact.\n",
    "It can be registered as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set ID:      72\n",
      "Data set version: ds_400e9f632a8448d08bc0da2e837b1096\n"
     ]
    }
   ],
   "source": [
    "date_set_version = add_suffix(\"ds\")\n",
    "\n",
    "data_set = exec.log_input(\n",
    "    metadata.DataSet(\n",
    "        description=\"Sample data\",\n",
    "        name=\"mnist-example\",\n",
    "        owner=\"mnist@kubeflow.com\",\n",
    "        uri=\"s3://mnist/mnist\",\n",
    "        version=date_set_version,\n",
    "        query=\"SELECT * FROM mnist\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Data set ID:      {data_set.id}\")\n",
    "print(f\"Data set version: {data_set.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data itself is available at the specified `uri`.\n",
    "The `query` is optional and _documents_ how this data is fetched from the source.\n",
    "It is not used to retrieve it.\n",
    "After all, the data does not have to live in a relational database at all.\n",
    "\n",
    "### How to Log a Model\n",
    "If a step of a machine learning workflow generates a model, it is logged as an output artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:      73\n",
      "Model version: model_715719fbdc81478db3a47e35e3e42220\n"
     ]
    }
   ],
   "source": [
    "model_version = add_suffix(\"model\")\n",
    "\n",
    "model = exec.log_output(\n",
    "    metadata.Model(\n",
    "        name=\"MNIST\",\n",
    "        description=\"Model to recognize handwritten digits\",\n",
    "        owner=\"owner@my-company.com\",\n",
    "        uri=\"s3://mnist/mnist\",\n",
    "        model_type=\"neural network\",\n",
    "        training_framework={\"name\": \"tensorflow\", \"version\": \"v1.0\"},\n",
    "        hyperparameters={\n",
    "            \"learning_rate\": 0.5,\n",
    "            \"layers\": [10, 3, 1],\n",
    "            \"early_stop\": True,\n",
    "        },\n",
    "        version=model_version,\n",
    "        labels={\"a_label\": \"some-value\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Model ID:      {model.id}\")\n",
    "print(f\"Model version: {model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How to Log the Evaluation of a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics ID: 74\n"
     ]
    }
   ],
   "source": [
    "metrics = exec.log_output(\n",
    "    metadata.Metrics(\n",
    "        name=\"MNIST evaluation\",\n",
    "        description=\"Evaluation of the MNIST model\",\n",
    "        owner=\"mnist@kubeflow.com\",\n",
    "        uri=\"s3://mnist/mnist\",\n",
    "        data_set_id=str(data_set.id),\n",
    "        model_id=str(model.id),\n",
    "        metrics_type=metadata.Metrics.VALIDATION,\n",
    "        values={\"accuracy\": 0.95},\n",
    "        labels={\"mylabel\": \"l1\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Metrics ID: {metrics.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Possible values for `metrics_type`:\n",
    "- `TRAINING`\n",
    "- `VALIDATION`\n",
    "- `TESTING`\n",
    "- `PRODUCTION`\n",
    "\n",
    "If you are not familiar with the distinction between validation and training, please check out the [notebook on hyperparameter tuning](../katib/Hyperparameter%20Tuning.ipynb), which explains the difference and the need for an additional evaluation step.\n",
    "\n",
    "## How to Add Metadata for Serving the Model\n",
    "Once you're satisfied with the model, you want to serve it.\n",
    "The model server is an execution with a model as input artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving model with ID:      75\n",
      "Serving model with version: model_715719fbdc81478db3a47e35e3e42220\n"
     ]
    }
   ],
   "source": [
    "app = metadata.Execution(\n",
    "    name=\"Serving the MNIST model\",\n",
    "    workspace=ws1,\n",
    "    description=\"An execution to represent the model serving component\",\n",
    ")\n",
    "\n",
    "served_model = metadata.Model(\n",
    "    name=\"MNIST\",\n",
    "    uri=\"s3://mnist/mnist\",\n",
    "    version=model.version,\n",
    ")\n",
    "\n",
    "m = app.log_input(served_model)\n",
    "\n",
    "print(f\"Serving model with ID:      {m.id}\")\n",
    "print(f\"Serving model with version: {m.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Please note that we use the `name`, `uri`, and `version` to identify the model.\n",
    "As stated before, only the first two are required, but it's a good practice to also include the version.\n",
    "\n",
    "## How to List All Models in a Workspace\n",
    "The Artifact Store is user interface that displays artifacts across all workspaces.\n",
    "Not all fields are available, which means we cannot filter easily on, say, custom labels.\n",
    "\n",
    "Fortunately, we can ask for all artifacts of a certain type: `Model`, `Metrics`, `DataSet`, or a custom artifact.\n",
    "Here's how to list all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = ws1.list(metadata.Model.ARTIFACT_TYPE_NAME)\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can see the output includes the labels.\n",
    "Labels are particularly helpful when monitoring many (versions of) models in production, both with regard to system and model performance, as both can affect the overall user experience; a bad prediction (e.g. recommendation) from a responsive service negatively affects the user experience, as does an unresponsive service with good predictions.\n",
    "Model as well as system performance metrics need to be tracked over time and across versions to ensure a solid user experience.\n",
    "With (shared) labels it's possible to monitor both simultaneously.\n",
    "\n",
    "## How to Track Lineage\n",
    "The same is true of executions and artifacts that belong to certain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_events = ws1.store.get_events_by_artifact_ids([model.id])\n",
    "\n",
    "execution_ids = set(e.execution_id for e in model_events)\n",
    "print(f\"Executions related to the model: {execution_ids}\")\n",
    "\n",
    "trainer_events = ws1.store.get_events_by_execution_ids([exec.id])\n",
    "artifact_ids = set(e.artifact_id for e in trainer_events)\n",
    "print(f\"Artifacts related to the trainer: {artifact_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Component 5: Serve the Model\n",
    "\n",
    "Kubeflow Pipelines comes with [a pre-defined KFServing component](https://raw.githubusercontent.com/kubeflow/pipelines/f21e0fe726f8aec86165beca061f64fa730e0ac7/components/kubeflow/kfserving/component.yaml) which can be imported from GitHub repo and reused across the pipelines without\n",
    "the need to define "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "it every time. We include a copy with the tutorial to make it work in an air-gapped environment.\n",
    "Here's what the import looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfserving = components.load_component_from_file(\"kfserving-component.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to Combine the Components into a Pipeline\n",
    "Note that up to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "this point we have not yet used the Kubeflow Pipelines SDK!\n",
    "\n",
    "With our four components (i.e. self-contained functions) defined, we can wire up the dependencies with Kubeflow Pipelines.\n",
    "\n",
    "The call [`components.func_to_container_op(f, base_image=img)(*args)`](https://www.kubeflow.org/docs/pipelines/sdk/sdk-overview/) has the following ingredients:\n",
    "- `f` is t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "he Python function that defines a component\n",
    "- `img` is the base (Docker) image used to package the function\n",
    "- `*args` lists the arguments to `f`\n",
    "\n",
    "What the `*args` mean is best explained by going forward through the graph:\n",
    "- `downloadOp` is the very first step and has no dependencies; it therefore has no `InputPath`.\n",
    "  Its output (i.e. `OutputPath`) is stored in `data_dir`.\n",
    "- `trainOp` needs the data downloaded from `downloadOp` and its signature lists `data_dir` (input) and `model_dir` (output).\n",
    "  So, it _depends on_ `downloadOp.output` (i.e. the previous step's output) and stores its own outputs in `model_dir`, which can be used by another step.\n",
    "  `downloadOp` is the parent of `trainOp`, as required.\n",
    "- `evaluateOp`'s function takes three arguments: `data_dir` (i.e. `downloadOp.output`), `model_dir` (i.e. `trainOp.output`), and `metrics_path`, which is where the function stores its evaluation metrics.\n",
    "  That way, `evaluateOp` can only run after the successful completion of both `downloadOp` and `trainOp`.\n",
    "- `exportOp` runs the function `export_model`, which accepts five parameters: `model_dir`, `metrics`, `export_bucket`, `model_name`, and `model_version`.\n",
    "  From where do we get the `model_dir`?\n",
    "  It is nothing but `trainOp.output`.\n",
    "  Similarly, `metrics` is `evaluateOp.output`.\n",
    "  The remaining three arguments are regular Python arguments that are static for the pipeline: they do not depend on any step's output being available.\n",
    "  Hence, they are defined without using `InputPath`.\n",
    "- `kfservingOp` is loaded from the external component and its order of execution should be specified explicitly by using `kfservingOp.after(evaluateOp)` function which assigns `exportOp` as a parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_serve(\n",
    "    data_dir: str,\n",
    "    model_dir: str,\n",
    "    export_bucket: str,\n",
    "    model_name: str,\n",
    "    model_version: int,\n",
    "):\n",
    "    # For GPU support, please add the \"-gpu\" suffix to the base image\n",
    "    BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-tensorflow-2.2.0\"\n",
    "\n",
    "    downloadOp = components.func_to_container_op(\n",
    "        download_dataset, base_image=BASE_IMAGE\n",
    "    )()\n",
    "\n",
    "    trainOp = components.func_to_container_op(train_model, base_image=BASE_IMAGE)(\n",
    "        downloadOp.output\n",
    "    )\n",
    "\n",
    "    evaluateOp = components.func_to_container_op(evaluate_model, base_image=BASE_IMAGE)(\n",
    "        downloadOp.output, trainOp.output\n",
    "    )\n",
    "\n",
    "    exportOp = components.func_to_container_op(export_model, base_image=BASE_IMAGE)(\n",
    "        trainOp.output, evaluateOp.output, export_bucket, model_name, model_version\n",
    "    )\n",
    "\n",
    "    kfservingOp = kfserving(\n",
    "        action=\"apply\",\n",
    "        model_name=\"mnist\",\n",
    "        default_model_uri=f\"https://mlopstestnplink.blob.core.windows.net/mnist\",\n",
    "        canary_model_traffic_percentage=\"10\",\n",
    "        namespace=\"kubeflow\",\n",
    "        framework=\"tensorflow\",\n",
    "        default_custom_model_spec=\"{}\",\n",
    "        canary_custom_model_spec=\"{}\",\n",
    "        autoscaling_target=\"0\",\n",
    "        kfserving_endpoint=\"\",\n",
    "    )\n",
    "\n",
    "    kfservingOp.after(exportOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def op_transformer(op):\n",
    "    op.add_pod_annotation(name=\"sidecar.istio.io/inject\", value=\"false\")\n",
    "    return op\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End-to-End MNIST Pipeline\",\n",
    "    description=\"A sample pipeline to demonstrate multi-step model training, evaluation, export, and serving\",\n",
    ")\n",
    "def mnist_pipeline(\n",
    "    model_dir: str = \"/train/model\",\n",
    "    data_dir: str = \"/train/data\",\n",
    "    export_bucket: str = \"mnist\",\n",
    "    model_name: str = \"mnist\",\n",
    "    model_version: int = 1,\n",
    "):\n",
    "    train_and_serve(\n",
    "        data_dir=data_dir,\n",
    "        model_dir=model_dir,\n",
    "        export_bucket=export_bucket,\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "    )\n",
    "    dsl.get_pipeline_conf().add_op_transformer(op_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "With that in place, let's submit the pipeline directly from our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_func = mnist_pipeline\n",
    "run_name = pipeline_func.__name__ + \" run\"\n",
    "experiment_name = \"End-to-End MNIST Pipeline\"\n",
    "\n",
    "arguments = {\n",
    "    \"model_dir\": \"/train/model\",\n",
    "    \"data_dir\": \"/train/data\",\n",
    "    \"export_bucket\": \"mnist\",\n",
    "    \"model_name\": \"mnist\",\n",
    "    \"model_version\": \"1\",\n",
    "}\n",
    "\n",
    "\n",
    "client = kfp.Client()\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    pipeline_func,\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    arguments=arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The graph will look like this:\n",
    "\n",
    "![Graph](./img/graph.png)\n",
    "\n",
    "If there are any issues with our pipeline definition, this is where they would flare up.\n",
    "So, until you submit it, you won't know if your pipeline definition is correct.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    We have so far claimed that Kubeflow Pipelines is for automation of multi-step (ad hoc) workflows and usage in CI/CD.\n",
    "    You may have wondered why that is.\n",
    "    After all, it is possible to set up <a href=\"https://www.kubeflow.org/docs/pipelines/overview/concepts/run/\">recurring runs</a> of pipelines.\n",
    "    The reason is that these pipeline steps are one-offs.\n",
    "    Even though you can parameterize each step, including the ones that kick off an entire pipeline, there is no orchestration of workflows.\n",
    "    Stated differently, if a step fails, there is no mechanism for automatic retries.\n",
    "    Nor is there any support for marking success: if the step is scheduled to be run again, it will be run again, whether or not the previous execution was successful, obviating any subsequent runs (except in cases where it may be warranted).\n",
    "    Kubeflow Pipelines allows <a href=\"https://www.kubeflow.org/docs/pipelines/reference/api/kubeflow-pipeline-api-spec/#operation--apis-v1beta1-runs--run_id--retry-post\">retries</a> but it is not configurable out of the box.\n",
    "    If you want Airflow- or Luigi-like behaviour for dependency management of workflows, Kubeflow Pipelines is not the tool.\n",
    "</div>\n",
    "\n",
    "## How to Predict with the Inference Server\n",
    "The simplest way to check that our inference server is up and running is to check it with `curl` ( pre-installed on the cluster).\n",
    "\n",
    "To do so, let's define a few helper functions for plotting and displaying images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_image(x_test, image_index):\n",
    "    plt.imshow(x_test[image_index].reshape(28, 28), cmap=\"binary\")\n",
    "\n",
    "def predict_number(model, x_test, image_index):\n",
    "    pred = model.predict(x_test[image_index : image_index + 1])\n",
    "    print(pred.argmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with np.load(\"datasets/mnist.npz\", allow_pickle=True) as f:\n",
    "    x_test = (\n",
    "        f[\"x_test\"] / 255.0\n",
    "    )  # We must transform the data in the same way as before!\n",
    "\n",
    "image_index = 1005\n",
    "\n",
    "display_image(x_test, image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Output](./img/9.png)\n",
    "\n",
    "The inference server expects a JSON payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import codecs, json\n",
    "\n",
    "tf_serving_req = {\"instances\": x_test[image_index : image_index + 1].tolist()}\n",
    "\n",
    "with open(\"input.json\", \"w\") as json_file:\n",
    "    json.dump(tf_serving_req, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "set -o errexit\n",
    "model=\"mnist\"\n",
    "url=\"mnist.kubeflow.svc.cluster.local/v1/models/mnist:predict\"\n",
    "\n",
    "curl --fail -L \"${url}\" -d@input.json -o output.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The probabilities for each class (0-9) are shown in the `predictions` response.\n",
    "The model believes the image shows a \"9\", which indeed it does!\n",
    "\n",
    "For more details on the URL, please check out this [example](https://github.com/kubeflow/kfserving/tree/master/docs/samples/tensorflow#run-a-prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gcr.io/arrikto/jupyter-kale:v0.5.0-47-g2427cc9",
   "experiment": {
    "id": "new",
    "name": "sagar1"
   },
   "experiment_name": "sagar1",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "sagar",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
