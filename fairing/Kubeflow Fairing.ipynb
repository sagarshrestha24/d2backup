{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have each Python cell auto-formatted\n",
    "# See: https://black.readthedocs.io\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Kubeflow Fairing does not support docker registries using a self-signed TLS certificate, certificate chaining nor insecure (plaintext HTTP) registries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Fairing: Build Docker Images from within Jupyter Notebooks\n",
    "\n",
    "## Introduction\n",
    "Although you can build Docker images by downloading files to your local machine and subsequently pushing the images to a container registry, it is much faster to do so without leaving Jupyter!\n",
    "[Kubeflow Fairing](https://www.kubeflow.org/docs/fairing/fairing-overview/) makes that possible.\n",
    "\n",
    "### What You'll Learn\n",
    "In this notebook we'll go through the steps involved in building a Docker image from a base image (e.g. TensorFlow or PyTorch) and a custom trainer file that defines your machine learning model.\n",
    "This image can be used for distributed training or [hyperparameter tuning](../katib/Hyperparameter%20Tuning.ipynb).\n",
    "You can use the model code you generated with `%%writefile` in [MNIST with TensorFlow tutorial](../training/tensorflow/MNIST%20with%20TensorFlow.ipynb) or [MNIST with PyTorch tutorial](../training/pytorch/MNIST%20with%20PyTorch.ipynb) or a file of your own choosing.\n",
    "\n",
    "The Docker image builder process stores (temporary) files in MinIO.\n",
    "[MinIO](https://min.io/), an open-source S3-compliant object storage tool, is already included with your Kubeflow installation.\n",
    "\n",
    "### What You'll Need\n",
    "\n",
    "- An executable Python file (e.g. an `mnist.py` trainer);\n",
    "- A container registry to which you have push access.\n",
    "\n",
    "Please note that this notebook is interactive!\n",
    "\n",
    "## Prerequisites\n",
    "Kubeflow Fairing must be installed, so let's check that it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show kubeflow-fairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training code and datasets\n",
    "The examples in this tutorial require a trainer code file `mnist.py` and a dataset to be present in the current folder.\n",
    "The code and datasets are already available in [MNIST with TensorFlow](../training/tensorflow/MNIST%20with%20TensorFlow.ipynb)\n",
    "or [MNIST with PyTorch](../training/pytorch/MNIST%20with%20PyTorch.ipynb) tutorials and can be reused here. Run one of the following shortcuts to copy the required files.\n",
    "\n",
    "##### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! jq -j '.cells[] | select(.metadata.tags!= null) | select (.metadata.tags[] | contains(\"trainer_code\")) | .source | .[]' ../training/tensorflow/MNIST\\ with\\ TensorFlow.ipynb | sed '1d' > mnist.py\n",
    "! cp -R ../training/tensorflow/datasets ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "! jq -j '.cells[] | select(.metadata.tags!= null) | select (.metadata.tags[] | contains(\"trainer_code\")) | .source | .[]' ../training/pytorch/MNIST\\ with\\ PyTorch.ipynb | sed '1d' > mnist.py\n",
    "! cp -R ../training/pytorch/datasets ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to go!\n",
    "\n",
    "## How to Create a Docker Credentials File and Kubernetes Secret\n",
    "\n",
    "We shall also require `getpass`, so that you can provide your password interactively without it being immediately visible.\n",
    "It's a standard Python library, so there is no need to install it.\n",
    "A simple `import` will suffice.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    We do not recommend you store passwords directly in notebooks.\n",
    "    Ideally, credentials are stored safely inside secrets management solutions or provided with service accounts.\n",
    "    This notebook should be used for demonstration purposes only!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type in the container registry username by running the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_user = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter the password for the container registry by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these details, we can base-64-encode the username and password and create a Kubernetes configmap with a name expected by the builder's context source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture creds --no-stderr\n",
    "! echo -n \"$docker_user:$docker_password\" | base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_credentials = creds.stdout.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = {\"auths\": {\"https://index.docker.io/v1/\": {\"auth\": docker_credentials}}}\n",
    "\n",
    "%store json.dumps(js) >config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl create configmap docker-config --from-file=config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Set up MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing import constants\n",
    "from kubeflow.fairing.builders.cluster.minio_context import MinioContextSource\n",
    "\n",
    "s3_endpoint = \"minio-service.kubeflow:9000\"\n",
    "s3_endpoint_url = f\"http://{s3_endpoint}\"\n",
    "s3_secret_id = \"minio\"\n",
    "s3_secret_key = \"minio123\"\n",
    "s3_region = \"us-east-1\"\n",
    "\n",
    "# The default Kaniko version (0.14.0) does not work with Kubeflow Fairing\n",
    "constants.constants.KANIKO_IMAGE = \"gcr.io/kaniko-project/executor:v0.19.0\"\n",
    "\n",
    "minio_context_source = MinioContextSource(\n",
    "    endpoint_url=s3_endpoint_url,\n",
    "    minio_secret=s3_secret_id,\n",
    "    minio_secret_key=s3_secret_key,\n",
    "    region_name=s3_region,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Build a Docker Image\n",
    "If you have your own container registry, please prepend it in `REGISTRY`.\n",
    "The `IMAGE_NAME` contains the name of the image that will be built and pushed to the `REGISTRY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY = \"mesosphere\"\n",
    "IMAGE_NAME = \"kubeflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your goal is to run a distributed training job _immediately_ from a notebook, we recommend the Option 1.\n",
    "With it, you build (and push) the image as a part of a deployment (e.g. distributed training job).\n",
    "\n",
    "If your goal is to provide a Docker image that includes the code for distributed training or hyperparameter tuning, Option 2 is more appropriate.\n",
    "It does not run the job (with pre-defined arguments) but merely pushes the image to the container registry.\n",
    "\n",
    "Both options automatically push the image to the registry specified.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" id=\"WARN\">\n",
    "    The Kubeflow Fairing API does <em>not</em> set the Docker image's entrypoint or command.\n",
    "    You can check that neither the <code>ENTRYPOINT</code> nor the <code>CMD</code> is not set with <code>docker inspect</code> on your local machine.\n",
    "    This means that you have to <a href=\"https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\">add the command</a> you want to run to your Kubernetes resource specification (YAML)!\n",
    "    Without this modification to the YAML your pods will fail to run their containerized workloads.\n",
    "    You can do this by adding the key <code>command</code> above the <code>args</code> specification:\n",
    "<code>\n",
    "containers:\n",
    "  - name: <name>\n",
    "    image: <docker-image-built-with-kubeflow-fairing>\n",
    "    <b>command:\n",
    "      - python\n",
    "      - -u\n",
    "      - mnist.py</b>\n",
    "    args:\n",
    "      - --epochs\n",
    "      - \"7\"\n",
    "    ...\n",
    "</code>        \n",
    "</div>\n",
    "\n",
    "### Option 1: Build-Push-Run\n",
    "Multiple input files (e.g. a trainer and utilities) can be provided in the `input_files` list.\n",
    "There can be only one `executable` file.\n",
    "With the `command` we must include all the mandatory arguments (i.e. `epochs`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow import fairing\n",
    "import glob\n",
    "\n",
    "fairing.config.set_preprocessor(\n",
    "    \"python\",\n",
    "    command=[\"python\", \"-u\", \"mnist.py\", \"--epochs=3\"],\n",
    "    input_files=[\"mnist.py\"] + glob.glob(\"datasets/**\", recursive=True),\n",
    "    path_prefix=\"/\",\n",
    "    executable=\"mnist.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow\n",
    "If your `mnist.py` file is based on TensorFlow, you must specify the appropriate base image for TensorFlow.\n",
    "In case you want to run the model on CPUs only, you ought to drop the `-gpu` suffix from the base image name.\n",
    "The primary configuration options are the chief and worker counts, but feel free to peruse all available parameters [here](https://github.com/kubeflow/fairing/blob/master/kubeflow/fairing/deployers/tfjob/tfjob.py).\n",
    "\n",
    "If your model code is based on PyTorch, please skip this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-tensorflow-2.2.0-gpu\"\n",
    "\n",
    "fairing.config.set_builder(\n",
    "    name=\"cluster\",\n",
    "    registry=REGISTRY,\n",
    "    base_image=BASE_IMAGE,\n",
    "    image_name=IMAGE_NAME,\n",
    "    context_source=minio_context_source,\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "    name=\"tfjob\",\n",
    "    worker_count=2,\n",
    "    chief_count=1,\n",
    "    # remove this parameter if the cluster doesn't have GPUs\n",
    "    pod_spec_mutators=[k8s_utils.get_resource_mutator(gpu=1)],\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "For a PyTorch-based `mnist.py` model, you must specify the appropriate base image for PyTorch.\n",
    "In case you want to run the model on CPUs and not GPUs, you simplify leave off the `-gpu` suffix from the base image's name.\n",
    "The main configuration options are the master and worker counts, but you can see all options [here](https://github.com/kubeflow/fairing/blob/master/kubeflow/fairing/deployers/pytorchjob/pytorchjob.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-pytorch-1.5.0-gpu\"\n",
    "\n",
    "fairing.config.set_builder(\n",
    "    name=\"cluster\",\n",
    "    registry=REGISTRY,\n",
    "    base_image=BASE_IMAGE,\n",
    "    image_name=IMAGE_NAME,\n",
    "    context_source=minio_context_source,\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "            name=\"pytorchjob\", \n",
    "            worker_count=2,\n",
    "            master_count=1,\n",
    "            # remove this parameter if the cluster doesn't have GPUs\n",
    "            pod_spec_mutators=[k8s_utils.get_resource_mutator(gpu=1)],\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Build-and-Push\n",
    "You can 'just' build a Docker image, that is, without running it by plugging it into a Kubeflow Fairing workflow, with the following snippet.\n",
    "Please choose the appropriate `BASE_IMAGE` based on whether your `mnist.py` file is a TensorFlow or PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.fairing.builders import cluster\n",
    "from kubeflow.fairing.preprocessors import base as base_preprocessor\n",
    "import glob\n",
    "\n",
    "# Choose which base image your executable mnist.py file requires\n",
    "BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-tensorflow-2.2.0-gpu\"\n",
    "# BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-pytorch-1.5.0-gpu\"\n",
    "\n",
    "preprocessor = base_preprocessor.BasePreProcessor(\n",
    "    input_files=[\"mnist.py\"] + glob.glob(\"datasets/**\", recursive=True), path_prefix=\"/\", executable=\"mnist.py\"\n",
    ")\n",
    "\n",
    "cluster_builder = cluster.cluster.ClusterBuilder(\n",
    "    registry=REGISTRY,\n",
    "    base_image=BASE_IMAGE,\n",
    "    preprocessor=preprocessor,\n",
    "    image_name=IMAGE_NAME,\n",
    "    context_source=minio_context_source,\n",
    ")\n",
    "\n",
    "cluster_builder.build()\n",
    "image_tag = cluster_builder.image_tag\n",
    "print(f\"Published Docker image with tag: {image_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the image is not run immediately, there is no need to specify a `deployer`.\n",
    "That is done with a YAML specification.\n",
    "Moreover, we also leave out the `command` in the preprocessor since Kubeflow Fairing does not set the entrypoint or executable command in the Docker image anyway.\n",
    "We have to manually do that in the <a href=\"#WARN\">specification</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gcr.io/arrikto/jupyter-kale:v0.5.0-47-g2427cc9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
